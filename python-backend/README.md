# Anclora Local Backend - FastAPI

Backend unificado que gestiona TTS, STT e Imagen para Anclora Adapt.

## Caracter√≠sticas

- üé§ **TTS (Text-to-Speech)**: Kokoro-82M - Voces naturales en espa√±ol
- üëÇ **STT (Speech-to-Text)**: Faster-Whisper Large-v3-Turbo - Transcripci√≥n r√°pida
- üé® **Imagen**: SDXL Lightning (4-step) - Generaci√≥n r√°pida de im√°genes
- ‚ö° **Gesti√≥n inteligente de VRAM**: Carga/descarga modelos seg√∫n se necesite
- üîß **Detecci√≥n autom√°tica de hardware**: Se adapta a tu RTX 3050 4GB

## Instalaci√≥n

### 1. Requisitos Previos

- Python 3.9+
- CUDA 12.1 (para GPU)
- 4GB VRAM m√≠nimo (RTX 3050)
- 32GB RAM recomendado

### 2. Crear Ambiente Virtual

```bash
cd python-backend
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

**Nota:** Primera instalaci√≥n toma 10-15 minutos por las dependencias de PyTorch y transformers.

### 4. Descargar Modelos

#### Kokoro TTS (REQUERIDO para funcionar)

El modelo Kokoro debe descargarse manualmente:

```bash
# Opci√≥n 1: Descarga manual desde HuggingFace
# Ir a: https://huggingface.co/hexgrad/Kokoro-82M
# Descargar:
#   - kokoro.onnx
#   - voices.json
# Colocar en: python-backend/models/

# Opci√≥n 2: Script de descarga autom√°tica (pr√≥ximamente)
python download_models.py
```

**Estructura esperada:**
```
python-backend/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ kokoro.onnx       ‚Üê Descargar
‚îÇ   ‚îî‚îÄ‚îÄ voices.json       ‚Üê Descargar
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## Ejecutar

```bash
# Terminal 1: Backend FastAPI
python main.py

# Salida esperada:
# üöÄ SERVIDOR ANCLORA BACKEND - INICIANDO
# üìç Escuchando en: http://0.0.0.0:8000
# üìä Documentaci√≥n: http://localhost:8000/docs
```

## Endpoints

### GET `/`
Informaci√≥n del servidor

```bash
curl http://localhost:8000/
```

### GET `/api/health`
Health check del backend

```bash
curl http://localhost:8000/api/health
```

**Respuesta:**
```json
{
  "status": "ok",
  "hardware": {
    "cpu_cores": 8,
    "ram_gb": 32.0,
    "gpu_model": "NVIDIA GeForce RTX 3050",
    "gpu_vram_gb": 4.0,
    "device": "cuda"
  }
}
```

### GET `/api/system/capabilities`
Detalles de capacidades del hardware

```bash
curl http://localhost:8000/api/system/capabilities
```

### POST `/api/tts`
Generar audio desde texto

```bash
curl -X POST "http://localhost:8000/api/tts" \
  -H "Content-Type: application/json" \
  -d '{
    "inputs": "Hola mundo",
    "language": "es",
    "voice_preset": "af_sarah"
  }' \
  --output audio.wav
```

**Par√°metros:**
- `inputs` (string, requerido): Texto a convertir a voz
- `language` (string, default: "es"): C√≥digo de idioma (es, en, fr, de, etc.)
- `voice_preset` (string, default: "af_sarah"): Voz a usar (depende de Kokoro)
- `model` (string, default: "kokoro"): Modelo a usar

**Respuesta:** Audio WAV en stream

### POST `/api/stt`
Transcribir audio

```bash
curl -X POST "http://localhost:8000/api/stt" \
  -F "file=@audio.wav"
```

**Par√°metros:**
- `file` (UploadFile, requerido): Archivo de audio

**Respuesta:**
```json
{
  "text": "Texto transcrito",
  "language": "es",
  "probability": 0.95
}
```

### POST `/api/image`
Generar imagen

```bash
curl -X POST "http://localhost:8000/api/image" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Un gato astronauta en el espacio",
    "negative_prompt": "baja calidad, borroso",
    "width": 1024,
    "height": 1024,
    "num_inference_steps": 4
  }' \
  --output image.png
```

**Par√°metros:**
- `prompt` (string, requerido): Descripci√≥n de la imagen
- `negative_prompt` (string, default: ""): Lo que NO debe aparecer
- `width` (int, default: 1024): Ancho en p√≠xeles
- `height` (int, default: 1024): Alto en p√≠xeles
- `num_inference_steps` (int, default: 4): Pasos de inferencia (4 para Lightning)

**Respuesta:** Imagen PNG en stream

## Documentaci√≥n Interactiva

Una vez el servidor est√° corriendo, accede a:

```
http://localhost:8000/docs
```

Swagger UI con todos los endpoints documentados y probables interactivamente.

## Troubleshooting

### Error: "Modelos Kokoro no encontrados"

**Causa:** Falta descargar los archivos de Kokoro

**Soluci√≥n:**
1. Ir a https://huggingface.co/hexgrad/Kokoro-82M
2. Descargar `kokoro.onnx` y `voices.json`
3. Colocar en `python-backend/models/`

### Error: "CUDA out of memory"

**Causa:** Tu RTX 3050 4GB se qued√≥ sin memoria

**Soluci√≥n:**
1. Cerrar otras aplicaciones que usan GPU (Chrome, games, Adobe)
2. Reducir tama√±o de imagen (width/height)
3. Usar CPU (m√°s lento): Editar `main.py`, cambiar `device` a "cpu"

### Error: "WhisperModel not found"

**Causa:** Falta descargar modelo de Whisper

**Soluci√≥n:** Es autom√°tico en primera ejecuci√≥n. Espera a que se descargue (~2GB).

### Servidor lento

**Causas comunes:**
- GPU completamente utilizada (reducir tama√±o de imagen)
- CPU sin suficientes n√∫cleos disponibles
- Disco duro lento (necesita m√°s RAM para cach√©)

**Soluciones:**
- Usar una imagen por vez
- Cerrar aplicaciones pesadas
- Esperar a que cache se genere (segunda llamada es m√°s r√°pida)

## Configuraci√≥n desde Frontend

Actualiza tu `.env.local`:

```bash
# Backend Unificado (Python FastAPI)
VITE_API_BASE_URL=http://localhost:8000

# Endpoints mapeados al backend unificado
VITE_TTS_ENDPOINT=http://localhost:8000/api/tts
VITE_STT_ENDPOINT=http://localhost:8000/api/stt
VITE_IMAGE_MODEL_ENDPOINT=http://localhost:8000/api/image
```

## Arquitectura

```
Backend (FastAPI)
‚îú‚îÄ‚îÄ ModelManager
‚îÇ   ‚îú‚îÄ‚îÄ TTS Kokoro (ligero, siempre cargado)
‚îÇ   ‚îú‚îÄ‚îÄ STT Whisper (carga bajo demanda)
‚îÇ   ‚îî‚îÄ‚îÄ Imagen SDXL Lightning (carga bajo demanda)
‚îÇ
‚îú‚îÄ‚îÄ CORS Middleware
‚îÇ   ‚îî‚îÄ‚îÄ Permite http://localhost:4173 (Vite)
‚îÇ
‚îî‚îÄ‚îÄ Endpoints REST
    ‚îú‚îÄ‚îÄ /api/tts ‚Üí TTS
    ‚îú‚îÄ‚îÄ /api/stt ‚Üí STT
    ‚îî‚îÄ‚îÄ /api/image ‚Üí Imagen
```

## Performance en RTX 3050 4GB

| Tarea | Tiempo | Notas |
|-------|--------|-------|
| **TTS (Kokoro)** | 0.5-1 seg | Ligero, siempre en memoria |
| **STT (Whisper)** | 2-5 seg | Primer audio lento (descarga modelo), pr√≥ximos r√°pidos |
| **Imagen (SDXL Lightning)** | 8-15 seg | 4 pasos, r√°pido para SDXL |

## Futuras Mejoras

- [ ] Download autom√°tico de modelos (script de setup)
- [ ] Cach√© de resultados frecuentes
- [ ] Soporte para m√∫ltiples voces Kokoro
- [ ] Integraci√≥n con Ollama para texto
- [ ] WebSocket para streaming de audio
- [ ] M√©tricas y monitoring

## Licencias

- FastAPI: MIT
- PyTorch: BSD
- Faster-Whisper: MIT
- Diffusers: Apache 2.0
- Kokoro: MIT

## Soporte

Para problemas, consulta:
1. Este README
2. `docs/Optimizacion-Anclora-Adapt-Definitivo-Gemini.md`
3. `docs/Backend_Unificado_en_Python_usando_FastAPI-Gemini.md`
