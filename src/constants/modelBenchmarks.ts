import type { ModelPerformanceMetrics } from "@/types/modelScoring";

export const MODEL_BENCHMARKS: Record<string, ModelPerformanceMetrics> = {
  "qwen2.5:7b-instruct": {
    mmluScore: 86.1,
    humanEvalScore: 79.8,
    mathScore: 83.1,
    tokensPerSecond: 22,
    firstTokenLatencyMs: 1400,
    avgTokenLatencyMs: 45,
    vramRequiredGB: 4.7,
    contextWindowSize: 128000,
    supportsLanguages: ["en", "es", "fr", "zh", "ja", "de", "it", "pt", "ar", "ru"],
    specializations: ["general", "instruction-following", "reasoning"],
    qualityRating: "excellent",
  },
  "mistral:latest": {
    mmluScore: 83.7,
    humanEvalScore: 78.2,
    mathScore: 79.5,
    tokensPerSecond: 25,
    firstTokenLatencyMs: 1200,
    avgTokenLatencyMs: 40,
    vramRequiredGB: 4.4,
    contextWindowSize: 32000,
    supportsLanguages: ["en", "es", "fr", "de", "it", "nl", "pt", "sv"],
    specializations: ["general", "instruction-following", "function-calling"],
    qualityRating: "very-good",
  },
  "llama3.2:latest": {
    mmluScore: 85.2,
    humanEvalScore: 80.5,
    mathScore: 81.0,
    tokensPerSecond: 20,
    firstTokenLatencyMs: 1300,
    avgTokenLatencyMs: 50,
    vramRequiredGB: 2.0,
    contextWindowSize: 131072,
    supportsLanguages: ["en", "es", "fr", "de", "it", "pt", "hi", "th", "ar"],
    specializations: ["general", "reasoning", "coding"],
    qualityRating: "very-good",
  },
  "gemma3:4b": {
    mmluScore: 77.8,
    humanEvalScore: 71.2,
    mathScore: 72.5,
    tokensPerSecond: 88,
    firstTokenLatencyMs: 800,
    avgTokenLatencyMs: 11.4,
    vramRequiredGB: 3.3,
    contextWindowSize: 8192,
    supportsLanguages: ["en", "es", "fr", "de", "it", "pt"],
    specializations: ["general", "instruction-following"],
    qualityRating: "good",
  },
  "phi3:3.8b-mini-128k-instruct-q4_K_M": {
    mmluScore: 75.3,
    humanEvalScore: 68.0,
    mathScore: 70.2,
    tokensPerSecond: 90,
    firstTokenLatencyMs: 750,
    avgTokenLatencyMs: 11.1,
    vramRequiredGB: 2.4,
    contextWindowSize: 131072,
    supportsLanguages: ["en"],
    specializations: ["instruction-following", "lightweight"],
    qualityRating: "good",
  },
  "qwen2.5:14b": {
    mmluScore: 87.3,
    humanEvalScore: 82.5,
    mathScore: 85.2,
    tokensPerSecond: 12,
    firstTokenLatencyMs: 2200,
    avgTokenLatencyMs: 83.3,
    vramRequiredGB: 9.0,
    contextWindowSize: 128000,
    supportsLanguages: [
      "en",
      "es",
      "fr",
      "zh",
      "ja",
      "de",
      "it",
      "pt",
      "ar",
      "ru",
      "hi",
    ],
    specializations: ["reasoning", "code", "math", "instruction-following"],
    qualityRating: "excellent",
  },
  "deepseek-r1:8b": {
    mmluScore: 84.5,
    humanEvalScore: 79.2,
    mathScore: 84.0,
    tokensPerSecond: 18,
    firstTokenLatencyMs: 1500,
    avgTokenLatencyMs: 55.6,
    vramRequiredGB: 5.2,
    contextWindowSize: 64000,
    supportsLanguages: ["en", "zh", "es"],
    specializations: ["reasoning", "math", "coding"],
    qualityRating: "very-good",
  },
  "phi4:14b": {
    mmluScore: 89.0,
    humanEvalScore: 82.0,
    mathScore: 86.7,
    tokensPerSecond: 6,
    firstTokenLatencyMs: 3200,
    avgTokenLatencyMs: 120,
    vramRequiredGB: 9.1,
    contextWindowSize: 131072,
    supportsLanguages: ["en", "es", "fr", "de"],
    specializations: ["reasoning", "math"],
    qualityRating: "excellent",
  },
  "qwen3-vl:8b": {
    mmluScore: 72,
    humanEvalScore: 70,
    mathScore: 68,
    tokensPerSecond: 18,
    firstTokenLatencyMs: 1800,
    avgTokenLatencyMs: 55,
    vramRequiredGB: 6.1,
    contextWindowSize: 128000,
    supportsLanguages: ["en", "es", "zh", "ja", "ar"],
    specializations: ["ocr", "visual-reasoning", "detail-extraction"],
    qualityRating: "excellent",
  },
  "gemma3:1b": {
    mmluScore: 70,
    humanEvalScore: 65,
    mathScore: 67,
    tokensPerSecond: 80,
    firstTokenLatencyMs: 900,
    avgTokenLatencyMs: 13,
    vramRequiredGB: 0.8,
    contextWindowSize: 8192,
    supportsLanguages: ["en", "es"],
    specializations: ["general", "instruction-following"],
    qualityRating: "good",
  },
  "llama2:latest": {
    mmluScore: 86.0,
    humanEvalScore: 80,
    mathScore: 81.5,
    tokensPerSecond: 20,
    firstTokenLatencyMs: 1500,
    avgTokenLatencyMs: 40,
    vramRequiredGB: 3.8,
    contextWindowSize: 32768,
    supportsLanguages: ["en", "es", "fr", "de", "it"],
    specializations: ["general", "reasoning"],
    qualityRating: "very-good",
  },
};
