# CONTEXTO DE CAMBIOS Y ESTADO

Documento vivo con el hist√≥rico de decisiones y el estado actual del proyecto.

---

## Resumen 2025-Q4

- **Backend textual** migrado definitivamente a Ollama local (Llama2/Mistral/Qwen) para evitar 404 de Hugging Face.
- **Refactor Front** en curso: la SPA qued√≥ dividida en modos y contextos (`InteractionContext`, `LanguageContext`, etc.).
- **Compatibilidad ling√º√≠stica**: la app ya sabe qu√© idiomas soporta cada modelo y autodetecta cu√°l usar cuando eliges ‚ÄúAuto‚Äù.
- **Historia reciente**:
  - Se habilit√≥ traducci√≥n literal en el modo B√°sico (JSON m√≠nimo).
  - Se a√±adi√≥ `lastModelUsed` en la UI para saber qu√© modelo respondi√≥ realmente.
  - Se deshabilitan idiomas no soportados seg√∫n el modelo instalado.
  - Se corrigi√≥ el layout (sin scroll indeseado, estilos consistentes).

---

## Camino hasta aqu√≠

### 1. De Hugging Face a Ollama (NOV-2025)
Problema original: `/api/hf-text` devolv√≠a 404 porque el router de Hugging Face retir√≥ varios endpoints legacy. Tras varios intentos (otros modelos, router nuevo, TogetherAI) se opt√≥ por **Ollama Local**:

```bash
ollama pull llama2
ollama serve
npm run dev
```

`callTextModel` ahora usa `POST /api/generate` de Ollama y `.env.local` solo define `VITE_OLLAMA_BASE_URL` y `VITE_TEXT_MODEL_ID`.

### 2. Refactor de la SPA (NOV-DIC 2025)
- Creaci√≥n de `src/` con componentes por modo (`BasicMode`, `CampaignMode`, etc.).
- Contextos globales (`InteractionContext`, `ThemeContext`, `LanguageContext`).
- Consolidaci√≥n de prompts y traducciones en `src/constants`.

### 3. Heur√≠stica de idioma/modelo (DIC 2025)
Casos como ‚Äútraduce al japon√©s‚Äù fallaban cuando Auto eleg√≠a `llama2`. Se a√±adi√≥:

1. **Mapa de capacidades** (`src/constants/modelCapabilities.ts`): define qu√© familias soportan CJK, cir√≠lico, etc.
2. **`resolveTextModelId` mejorado**: si el usuario pide japon√©s y est√° instalado un modelo tipo Qwen, se selecciona autom√°ticamente.
3. **Selectores adaptativos**: los desplegables de idioma muestran solo los idiomas permitidos por el modelo actual. Con ‚ÄúAuto‚Äù se muestran todos, pero los no soportados se deshabilitan hasta que instales un modelo compatible.
4. **`lastModelUsed`** visible bajo el combo para saber qu√© modelo respondi√≥ realmente.

### 4. Ajustes de UX recientes
- Layout sin scroll vertical extra (los frames ya no se desbordan).
- Bot√≥n ‚ÄúCopiar‚Äù ahora tiene contraste alto en modo oscuro.
- El modo B√°sico produce traducciones literales limpias (JSON con un √∫nico `content`).

---

## Estado actual por √°reas

| √Årea | Estado | Comentario |
|------|--------|------------|
| Generaci√≥n de texto | ‚úÖ Estable con Ollama | Modelos recomendados: `llama2`, `mistral`, `qwen2.5:7b` (para japon√©s/chino/ruso). |
| Traducciones | ‚úÖ | El modo B√°sico fuerza JSON limpio y la app elige el modelo multiling√ºe adecuado. |
| Selecci√≥n de idioma | ‚úÖ Adaptativo | Los idiomas no soportados aparecen deshabilitados cuando el modelo seleccionado no los cubre. |
| Mostrar modelo usado | ‚úÖ | `lastModelUsed` se actualiza tras cada generaci√≥n (visible bajo ‚ÄúModelo de texto‚Äù). |
| Imagen / Voz / STT | ‚ö†Ô∏è Pendiente | Hooks listos pero faltan endpoints reales (FastAPI opcional). |
| Refactor front | üü° En progreso | Falta completar la migraci√≥n de algunos modos legacy y a√±adir tests. |
| Tests automatizados | ‚ùå | Vitest configurado pero sin cobertura a√∫n. |
| Backend persistente | ‚ùå | Actualmente todo es local (sin DB). |
| CI/CD | ‚ùå | Builds manuales. |

---

## Modelos soportados y idiomas

| Modelo / Familia | Idiomas confirmados |
|------------------|--------------------|
| `llama2`, `llama3`, `mistral`, `gemma` | ES, EN, FR, DE, PT, IT, RU |
| `qwen2.5`, `yi`, `deepseek` | Todo lo anterior + JA, ZH |
| Otros (phi, orca, neural-chat) | ES, EN, FR, DE, PT, IT |

> Si instalas un modelo nuevo y pulsas ‚ÄúActualizar modelos‚Äù la app recalcula autom√°ticamente el soporte ling√º√≠stico. Para habilitar japon√©s/chino instala un Qwen o Yi (`ollama pull qwen2.5:7b`). Si no hay modelo compatible, la opci√≥n aparece deshabilitada.

---

## Pr√≥ximos pasos sugeridos

1. **Implementar imagen/TTS/STT** con el backend FastAPI incluido en `python-backend/`.
2. **Tests** de regresi√≥n para cada modo (Vitest + React Testing Library).
3. **Persistencia** (FastAPI/Node + DB ligera) para guardar sesiones/resultados.
4. **Informes de uso** (cu√°ntas generaciones por modo/modelo).
5. **CI/CD** con GitHub Actions para lint + tests antes de merge.

---

## Notas operativas

- `.env.local` de ejemplo est√° en la ra√≠z. No requiere claves externas salvo que conectes un backend distinto.
- Para depurar, usa `npm run check:health` (valida Ollama y endpoints opcionales).
- Cualquier cambio en estilos debe pasar por `src/styles/commonStyles.ts` para mantener coherencia claro/oscuro.
- Antes de a√±adir un idioma nuevo aseg√∫rate de extender `capabilityMatrix` con el modelo que lo soporta.

---

## TL;DR

- Ya no dependemos de endpoints externos: todo corre en Ollama local.
- La app sabe qu√© modelo usar seg√∫n el idioma solicitado y se lo comunica al usuario.
- Las traducciones literal/estructurada vuelven a ser fiables.
- Falta completar modos avanzados, tests y backend persistente, pero la base es estable para trabajo diario.
