# CONTEXTO DE CAMBIOS Y ESTADO

Documento vivo con el hist√≥rico de decisiones y el estado actual del proyecto.  
√öltima revisi√≥n: **diciembre 2025**.

---

## Resumen actual

- **Backend textual** se ejecuta 100‚ÄØ% en **Ollama local** (Llama2/Mistral/Qwen). Sin dependencias externas, sin rate limits.
- **SPA modular** (React + Vite) organizada en modos (`BasicMode`, `CampaignMode`, etc.) y contextos globales (`InteractionContext`, `ThemeContext`, `LanguageContext`).
- **Compatibilidad ling√º√≠stica** din√°mica: la app detecta qu√© modelos tienes instalados y habilita s√≥lo los idiomas que soportan. Cuando eliges ‚ÄúAuto‚Äù, el selector muestra los idiomas disponibles y deshabilita el resto (con un tooltip).
- **Mejoras recientes de UX**:
  - Layout sin scroll vertical extra; los botones y campos se muestran completos en 1080p.
  - Bot√≥n ‚ÄúCopiar‚Äù y el toggle de idioma tienen contraste correcto en claro/oscuro.
  - El modo B√°sico ofrece ‚ÄúGenerar traducci√≥n‚Äù cuando fuerzas traducci√≥n literal y produce JSON limpio (un √∫nico `content`).
  - `lastModelUsed` se muestra bajo ‚ÄúModelo de texto‚Äù para saber qu√© modelo respondi√≥ realmente.
- **Backend FastAPI** (`python-backend`) expone `/api/tts`, `/api/stt`, `/api/image` y `/api/voices`. Se integra con Kokoro (ONNX), Whisper y Stable Diffusion (pendiente de pulir modelos/descargas).

---

## Camino hasta aqu√≠

### 1. Migraci√≥n a Ollama (noviembre 2025)
El endpoint `/api/hf-text` devolv√≠a 404 porque Hugging Face retir√≥ `api-inference`. Tras varios intentos (router nuevo, TogetherAI) se migr√≥ a **Ollama**:

```bash
ollama pull llama2
ollama serve   # o el script manage-ollama.ps1
npm run dev
```

El front usa ahora `POST /api/generate` y `.env.local` solo necesita:

```ini
VITE_OLLAMA_BASE_URL=http://localhost:11434
VITE_TEXT_MODEL_ID=llama2   # se puede cambiar a mistral, qwen, etc.
```

### 2. Refactor de la SPA
- Creaci√≥n de `src/` con componentes separados por modo.
- Contextos globales para estado (modo activo, outputs, idioma, tema).
- Prompts/traducciones centralizados en `src/constants`.

### 3. Heur√≠stica de idioma/modelo
- `src/constants/modelCapabilities.ts`: define qu√© familias soportan CJK, cir√≠lico, etc.
- `resolveTextModelId` intenta Qwen/Yi cuando se solicita japon√©s/chino/ruso.
- El selector de idioma se alimenta con `buildLanguageOptions`: deshabilita idiomas no soportados y muestra tooltips explicativos.
- Se registra `lastModelUsed` para ense√±ar al usuario qu√© modelo se us√≥ realmente incluso en modo ‚ÄúAuto‚Äù.

### 4. Ajustes de interfaz
- Bot√≥n ‚ÄúCopiar‚Äù y toggle de idioma con estilos uniformes.
- ‚ÄúGenerar traducci√≥n‚Äù cuando activas el checkbox de traducci√≥n literal.
- Script `scripts/manage-ollama.ps1` para listar modelos, precargar el seleccionado y reiniciar el daemon sin procesos hu√©rfanos.

---

## Estado por √°reas

| √Årea | Estado | Comentario |
|------|--------|------------|
| ‚úçÔ∏è Generaci√≥n de texto | ‚úÖ Estable | Modelos recomendados: `llama2`, `mistral`, `qwen2.5:7b` (CJK). |
| üåê Traducci√≥n literal | ‚úÖ | JSON limpio; se selecciona modelo multiling√ºe autom√°ticamente. |
| üåç Selector de idiomas | ‚úÖ Adaptativo | Idiomas no soportados aparecen deshabilitados con tooltip. |
| üìä Modelo usado | ‚úÖ | Visible bajo ‚ÄúModelo de texto‚Äù. |
| üé® Imagen / üîä Voz / üó£Ô∏è STT | ‚ö†Ô∏è Pendiente | FastAPI expone endpoints, pero falta afinar modelos (Kokoro/Whisper/SD). |
| üß© Refactor front | üü° En progreso | Algunos modos legacy requieren limpieza y tests. |
| ‚úÖ Tests automatizados | ‚ùå | Vitest configurado, pero sin suites a√∫n. |
| üóÑÔ∏è Persistencia | ‚ùå | No hay DB; todo se mantiene en localStorage. |
| üîÅ CI/CD | ‚ùå | Builds y merges manuales (sin GitHub Actions todav√≠a). |

---

## Modelos e idiomas soportados

| Familia / Modelo | Idiomas |
|------------------|---------|
| `llama2`, `llama3`, `mistral`, `gemma` | ES, EN, FR, DE, PT, IT, RU |
| `qwen2.5`, `yi`, `deepseek` | Todo lo anterior + JA, ZH |
| `phi`, `orca`, `neural-chat` | ES, EN, FR, DE, PT, IT |

> Tras pulsar ‚ÄúActualizar modelos‚Äù, la app recalcula la cobertura. Si faltan idiomas (por ejemplo japon√©s), instala un modelo compatible (`ollama pull qwen2.5:7b`). El selector mostrar√° esos idiomas en cuanto el modelo est√© disponible.

---

## Pr√≥ximos pasos sugeridos

1. **Backend creativo**: completar la integraci√≥n de Kokoro (descarga `kokoro.onnx` + `voices.json` en `python-backend/models/`) y ajustar Stable Diffusion en `/api/image`.
2. **Tests de regresi√≥n**: cobertura m√≠nima para los modos cr√≠ticos (`BasicMode`, `CampaignMode`, `ChatMode`).
3. **Persistencia y sesiones**: guardar prompts/outputs en una base ligera (SQLite/Postgres) y permitir historial.
4. **Observabilidad**: m√©tricas b√°sicas (conteo de generaciones por modo/modelo) y logs estructurados.
5. **CI/CD**: pipeline de GitHub Actions con lint + tests antes de mergear en `development`.
6. **Optimizaci√≥n de assets**: revisar bundle y lazy loading m√°s granular (solo si no afecta UX).

---

## Notas operativas

- `.env.local` en la ra√≠z; no expone credenciales sensibles salvo que conectes backends externos.
- Para comprobar servicios locales, usa `npm run check:health`.
- Cambios en estilos van a `src/styles/commonStyles.ts` para mantener consistencia claro/oscuro.
- Antes de a√±adir un idioma nuevo, extiende `capabilityMatrix` con el modelo que lo soporta; de lo contrario aparecer√° deshabilitado.
- Script √∫til: `.\scripts\manage-ollama.ps1` (PowerShell) lista modelos, precarga el seleccionado y reinicia `ollama serve`.

---

## TL;DR

- El front ya no depende de servicios externos: todo corre en Ollama + FastAPI locales.
- La UI se adapta al modelo instalado (idiomas, modelo usado, traducciones literales fiables).
- Falta completar el backend multimedia, a√±adir tests y automatizar la entrega, pero la base es estable para trabajo diario.  
- Siguiente hito: cerrar la integraci√≥n de Kokoro/Whisper/SDXL y a√±adir pruebas automatizadas.
